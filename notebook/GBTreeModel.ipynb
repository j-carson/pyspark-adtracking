{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBTree Model\n",
    "\n",
    "Tuning and testing a GBTree model (most promising after MVP step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspark 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x10b4dbf28>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.sql.SparkSession.builder.config('spark.driver.memory', '8g')\n",
    "pyspark.sql.SparkSession.builder.config('spark.sql.shuffle.paritions', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and do some class rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18444704, 456846)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 10 percent of class 0, and all of class 1 \n",
    "class0 = spark.read.parquet('../data/model/train0_10pctf.parquet')\n",
    "class1 = spark.read.parquet('../data/model/train1f.parquet')\n",
    "\n",
    "class0.count(), class1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607891, 457005)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downsample majority, bootstrap minority\n",
    "resam0 = class0.sample(fraction=.033, withReplacement=False)\n",
    "resam1 = class1.sample(fraction=1., withReplacement=True)\n",
    "resam0.count(), resam1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = resam1.unionAll(resam0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble for Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ dt[0] for dt in df.dtypes ]\n",
    "\n",
    "# these aren't predictors or targets\n",
    "columns.remove('index')\n",
    "columns.remove('ip')\n",
    "columns.remove('channel')\n",
    "columns.remove('app')\n",
    "columns.remove('device')\n",
    "columns.remove('os')\n",
    "columns.remove('click_time')\n",
    "columns.remove('attributed_time')\n",
    "columns.remove('doy')\n",
    "\n",
    "df = df[[columns]]\n",
    "\n",
    "columns.remove('is_attributed')\n",
    "\n",
    "vec_assembler = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "vf = vec_assembler.transform(df)\n",
    "vf = vf[['is_attributed', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol = 'is_attributed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtc = GBTClassifier(\n",
    "    labelCol = 'is_attributed',\n",
    ")\n",
    "\n",
    "pg = ParamGridBuilder(\n",
    "       ).addGrid(\n",
    "                gbtc.maxDepth, [8]\n",
    "       ).addGrid( \n",
    "                gbtc.minInstancesPerNode, [16] \n",
    "       ).addGrid(\n",
    "                gbtc.maxIter, [15]\n",
    "       ).addGrid(\n",
    "                gbtc.stepSize, [ .7 ]\n",
    "       ).addGrid(\n",
    "                gbtc.subsamplingRate, [ .9 ]\n",
    "       ).addGrid(\n",
    "                gbtc.featureSubsetStrategy, [ '13' ]\n",
    "       ).build(\n",
    "       )\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "        estimator = gbtc,\n",
    "        estimatorParamMaps = pg,\n",
    "        evaluator = evaluator,\n",
    "        trainRatio = .8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748328509595653"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model = tvs.fit(vf)\n",
    "\n",
    "results = tvs_model.transform(vf)\n",
    "evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we downsampled, running on the full training set is testing with new data \n",
    "full = spark.read.parquet('../data/model/trainf.parquet')\n",
    "\n",
    "fullvf = vec_assembler.transform(full)\n",
    "fullvf = fullvf[['is_attributed', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740937381488518"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_model = tvs_model.bestModel\n",
    "results = gbt_model.transform(fullvf)\n",
    "evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like it generalized OK so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(is_attributed=1, prediction=0.0, count=53071),\n",
       " Row(is_attributed=0, prediction=0.0, count=179173626),\n",
       " Row(is_attributed=1, prediction=1.0, count=403775),\n",
       " Row(is_attributed=0, prediction=1.0, count=5273418)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = results.groupby(['is_attributed','prediction']).count().collect()\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second model with just top 10 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0013476903384891969, 'tgt_device_pct'),\n",
       " (0.0014580234138776291, 'device_pct'),\n",
       " (0.010024484902413755, 'tgt_device_channel'),\n",
       " (0.01608814016932691, 'device_channel'),\n",
       " (0.016826250113733888, 'tgt_app_pct'),\n",
       " (0.01751087810005689, 'tgt_os_pct'),\n",
       " (0.017569781087630767, 'os_pct'),\n",
       " (0.017691586003965257, 'device_os'),\n",
       " (0.020372078239269755, 'tgt_device_os'),\n",
       " (0.020448219420355865, 'tgt_device_app'),\n",
       " (0.022272101207732594, 'channel_pct'),\n",
       " (0.023659318440610207, 'os_app'),\n",
       " (0.03072809073544542, 'os_channel'),\n",
       " (0.042281924453536096, 'channel_app'),\n",
       " (0.04264979607987805, 'device_app'),\n",
       " (0.05386578186496301, 'tgt_os_app'),\n",
       " (0.05681795921365693, 'tgt_channel_app'),\n",
       " (0.05897792377674138, 'tgt_os_channel'),\n",
       " (0.10872088517503842, 'tgt_channel_pct'),\n",
       " (0.146796432474551, 'ip_pct'),\n",
       " (0.27389265478872715, 'app_pct')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filist = sorted(list(zip(tvs_model.bestModel.featureImportances,columns)))\n",
    "filist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['os_app',\n",
       " 'os_channel',\n",
       " 'channel_app',\n",
       " 'device_app',\n",
       " 'tgt_os_app',\n",
       " 'tgt_channel_app',\n",
       " 'tgt_os_channel',\n",
       " 'tgt_channel_pct',\n",
       " 'ip_pct',\n",
       " 'app_pct']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_cols =  [ t[1] for t in filist[-10:]]\n",
    "top_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble most important features for Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_assembler = VectorAssembler(inputCols=top_cols, outputCol='features')\n",
    "tvf = top_assembler.transform(df)\n",
    "tvf = tvf[['is_attributed', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9746221678309072"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtc = GBTClassifier(\n",
    "    labelCol = 'is_attributed',\n",
    ")\n",
    "\n",
    "pg = ParamGridBuilder(\n",
    "       ).addGrid(\n",
    "                gbtc.maxDepth, [8]\n",
    "       ).addGrid( \n",
    "                gbtc.minInstancesPerNode, [16] \n",
    "       ).addGrid(\n",
    "                gbtc.maxIter, [15]\n",
    "       ).addGrid(\n",
    "                gbtc.stepSize, [ .7  ]\n",
    "       ).addGrid(\n",
    "                gbtc.subsamplingRate, [ .9 ]\n",
    "       ).addGrid(\n",
    "                gbtc.featureSubsetStrategy, [ '9' ]\n",
    "       ).build(\n",
    "       )\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "        estimator = gbtc,\n",
    "        estimatorParamMaps = pg,\n",
    "        evaluator = evaluator,\n",
    "        trainRatio = .8\n",
    "    )\n",
    "\n",
    "tvs_model = tvs.fit(tvf)\n",
    "results = tvs_model.transform(tvf)\n",
    "evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.973878306276408"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvf_full = top_assembler.transform(full)\n",
    "gbt_model = tvs_model.bestModel\n",
    "results = gbt_model.transform(tvf_full)\n",
    "evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(is_attributed=1, prediction=0.0, count=53385),\n",
       " Row(is_attributed=0, prediction=0.0, count=179295637),\n",
       " Row(is_attributed=1, prediction=1.0, count=403461),\n",
       " Row(is_attributed=0, prediction=1.0, count=5151407)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = results.groupby(['is_attributed','prediction']).count().collect()\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results are roughly comparable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-5572cac05c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# barrier so I don't hit return too many times and kill my spark session :-)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# barrier so I don't hit return too many times and kill my spark session :-)\n",
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

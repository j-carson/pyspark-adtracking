{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP\n",
    "\n",
    "## Minimum Viable Project\n",
    "\n",
    "Taking my features and running the toy sample data through the pyspark classifiers to see which looks most promising.\n",
    "\n",
    "From this notebook, selected the GBTree model as the one to train/tune with more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "pyspark 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x10def3d68>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment these out to run on a cluster. Also, adjust memory to size of your laptop\n",
    "pyspark.sql.SparkSession.builder.config('spark.driver.memory', '8g')\n",
    "pyspark.sql.SparkSession.builder.config('spark.sql.shuffle.paritions', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the (feature-engineered) 'train_sample' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('../data/model/train_samplef.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ dt[0] for dt in df.dtypes ]\n",
    "\n",
    "columns.remove('ip')\n",
    "columns.remove('channel')\n",
    "columns.remove('app')\n",
    "columns.remove('device')\n",
    "columns.remove('os')\n",
    "columns.remove('click_time')\n",
    "columns.remove('attributed_time')\n",
    "columns.remove('doy')\n",
    "\n",
    "df = df[[columns]]\n",
    "\n",
    "columns.remove('is_attributed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|is_attributed|count|\n",
      "+-------------+-----+\n",
      "|            1|  227|\n",
      "|            0|99773|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('is_attributed').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|is_attributed|            features|\n",
      "+-------------+--------------------+\n",
      "|            0|[1.0,0.9004319731...|\n",
      "|            0|[1.0,0.2181837572...|\n",
      "+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=columns, outputCol='features')\n",
    "vf = vec_assembler.transform(df)\n",
    "vf = vf[['is_attributed', 'features']]\n",
    "vf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol = 'is_attributed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9376391457065689"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    labelCol = 'is_attributed',\n",
    ")\n",
    "\n",
    "# Preparting for future hyperparameter tuning\n",
    "pg = ParamGridBuilder(\n",
    "       ).addGrid(\n",
    "                rfc.numTrees, [20]\n",
    "       ).addGrid(\n",
    "                rfc.maxDepth, [5, 7]\n",
    "       ).addGrid(\n",
    "                rfc.minInstancesPerNode, [32]\n",
    "       ).addGrid(\n",
    "                rfc.maxBins, [128]\n",
    "       ).addGrid(\n",
    "                rfc.subsamplingRate, [.8 ]\n",
    "       ).addGrid(\n",
    "                rfc.featureSubsetStrategy, [ '.75' ]\n",
    "       ).build(\n",
    "       )\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "        estimator = rfc,\n",
    "        estimatorParamMaps = pg,\n",
    "        evaluator = evaluator,\n",
    "        trainRatio = .8\n",
    "    )\n",
    "\n",
    "tvs_model = tvs.fit(vf)\n",
    "results = tvs_model.transform(vf)\n",
    "evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacheNodeIds False\n",
      "checkpointInterval 10\n",
      "featureSubsetStrategy .75\n",
      "featuresCol features\n",
      "impurity gini\n",
      "labelCol is_attributed\n",
      "maxBins 128\n",
      "maxDepth 5\n",
      "maxMemoryInMB 256\n",
      "minInfoGain 0.0\n",
      "minInstancesPerNode 32\n",
      "numTrees 20\n",
      "predictionCol prediction\n",
      "probabilityCol probability\n",
      "rawPredictionCol rawPrediction\n",
      "seed -2595380024694023377\n",
      "subsamplingRate 0.8\n"
     ]
    }
   ],
   "source": [
    "params = tvs_model.bestModel.extractParamMap()\n",
    "for k in params.keys():\n",
    "    print(k.name, params[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994050326841048"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtc = GBTClassifier(\n",
    "    labelCol = 'is_attributed',\n",
    ")\n",
    "\n",
    "# Preparting for future hyperparameter tuning\n",
    "pg = ParamGridBuilder(\n",
    "       ).addGrid(\n",
    "                gbtc.maxDepth, [8]\n",
    "       ).addGrid(\n",
    "                gbtc.minInstancesPerNode, [32]\n",
    "       ).addGrid(\n",
    "                gbtc.maxIter, [10]\n",
    "       ).addGrid(\n",
    "                gbtc.subsamplingRate, [.8 ]\n",
    "       ).addGrid(\n",
    "                gbtc.featureSubsetStrategy, ['.5', '.7', '.9']\n",
    "       ).build(\n",
    "       )\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "        estimator = gbtc,\n",
    "        estimatorParamMaps = pg,\n",
    "        evaluator = evaluator,\n",
    "        trainRatio = .8\n",
    "    )\n",
    "\n",
    "tvs_model = tvs.fit(vf)\n",
    "results = tvs_model.transform(vf)\n",
    "evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cacheNodeIds False\n",
      "checkpointInterval 10\n",
      "featureSubsetStrategy .5\n",
      "featuresCol features\n",
      "labelCol is_attributed\n",
      "lossType logistic\n",
      "maxBins 32\n",
      "maxDepth 8\n",
      "maxIter 10\n",
      "maxMemoryInMB 256\n",
      "minInfoGain 0.0\n",
      "minInstancesPerNode 32\n",
      "predictionCol prediction\n",
      "seed -5542985121037825445\n",
      "stepSize 0.1\n",
      "subsamplingRate 0.8\n"
     ]
    }
   ],
   "source": [
    "params = tvs_model.bestModel.extractParamMap()\n",
    "for k in params.keys():\n",
    "    print(k.name, params[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689324060765065"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc = MultilayerPerceptronClassifier(\n",
    "    labelCol = 'is_attributed',\n",
    ")\n",
    "\n",
    "pg = ParamGridBuilder(\n",
    "       ).addGrid(\n",
    "            mlpc.solver, ['l-bfgs']\n",
    "       ).addGrid(\n",
    "            mlpc.layers, \n",
    "                [ (21,10,2), (21,15,2), (21,20,2) ]\n",
    "       ).build(\n",
    "       )\n",
    "\n",
    "tvs = TrainValidationSplit(\n",
    "        estimator = mlpc,\n",
    "        estimatorParamMaps = pg,\n",
    "        evaluator = evaluator,\n",
    "        trainRatio = .8\n",
    "    )\n",
    "\n",
    "tvs_model = tvs.fit(vf)\n",
    "results = tvs_model.transform(vf)\n",
    "evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 15, 2]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.bestModel.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5572cac05c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# barrier so I don't hit return too many times and kill my spark session :-)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# barrier so I don't hit return too many times and kill my spark session :-)\n",
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Submission\n",
    "\n",
    "The holdout is held by Kaggle, which wants answers uploaded in a particular format.\n",
    "\n",
    "Using the best hyperparameters from the GBTree notebook:\n",
    "1. Create three test sets with different random seeds\n",
    "2. Train three models \n",
    "3. Run the kaggle test set through the three models\n",
    "4. Choose the median answer as the final answer\n",
    "5. Upload to kaggle to see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import GBTClassificationModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy   1.16.2\n",
      "pandas  0.24.2\n",
      "pyspark 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x10e87fc18>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment these out to run on a cluster. Also, adjust memory to size of your laptop\n",
    "pyspark.sql.SparkSession.builder.config('spark.driver.memory', '8g')\n",
    "pyspark.sql.SparkSession.builder.config('spark.sql.shuffle.paritions', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and do some class rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18444704, 456846, 18790469)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 10 percent of class 0, and all of class 1 \n",
    "class0 = spark.read.parquet('../data/model/train0_10pctf.parquet')\n",
    "class1 = spark.read.parquet('../data/model/train1f.parquet')\n",
    "test = spark.read.parquet('../data/model/testf.parquet')\n",
    "\n",
    "class0.count(), class1.count(), test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample majority, bootstrap minority\n",
    "resam0_a = class0.sample(fraction=.033, withReplacement=False, seed=111)\n",
    "resam1_a = class1.sample(fraction=1., withReplacement=True, seed=111)\n",
    "df_a = resam0_a.unionAll(resam1_a)\n",
    "\n",
    "resam0_b = class0.sample(fraction=.033, withReplacement=False, seed=222)\n",
    "resam1_b = class1.sample(fraction=1., withReplacement=True, seed=222)\n",
    "df_b = resam0_b.unionAll(resam1_b)\n",
    "\n",
    "resam0_c = class0.sample(fraction=.033, withReplacement=False, seed=333)\n",
    "resam1_c = class1.sample(fraction=1., withReplacement=True, seed=333)\n",
    "df_c = resam0_c.unionAll(resam1_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble for Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ dt[0] for dt in df_a.dtypes ]\n",
    "\n",
    "columns.remove('index')\n",
    "columns.remove('ip')\n",
    "columns.remove('channel')\n",
    "columns.remove('app')\n",
    "columns.remove('device')\n",
    "columns.remove('os')\n",
    "columns.remove('click_time')\n",
    "columns.remove('attributed_time')\n",
    "columns.remove('doy')\n",
    "columns.remove('is_attributed')\n",
    "\n",
    "vec_assembler = VectorAssembler(inputCols=columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_a = vec_assembler.transform(df_a)\n",
    "vf_a = vf_a[['is_attributed', 'features']]\n",
    "\n",
    "vf_b = vec_assembler.transform(df_b)\n",
    "vf_b = vf_b[['is_attributed', 'features']]\n",
    "\n",
    "vf_c = vec_assembler.transform(df_c)\n",
    "vf_c = vf_c[['is_attributed', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf_test = vec_assembler.transform(test)\n",
    "vf_test = vf_test[['click_id', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble for Spark - top 10 features version\n",
    "top_cols = ['os_app',\n",
    " 'os_channel',\n",
    " 'channel_app',\n",
    " 'device_app',\n",
    " 'tgt_os_app',\n",
    " 'tgt_channel_app',\n",
    " 'tgt_os_channel',\n",
    " 'tgt_channel_pct',\n",
    " 'ip_pct',\n",
    " 'app_pct']\n",
    "top_assembler = VectorAssembler(inputCols=top_cols, outputCol = 'features')\n",
    "\n",
    "topv_a = top_assembler.transform(df_a)\n",
    "topv_a = topv_a[['is_attributed','features']]\n",
    "\n",
    "topv_b = top_assembler.transform(df_b)\n",
    "topv_b = topv_b[['is_attributed','features']]\n",
    "\n",
    "topv_c = top_assembler.transform(df_c)\n",
    "topv_c = topv_c[['is_attributed','features']]\n",
    "\n",
    "topv_test = top_assembler.transform(test)\n",
    "topv_test = topv_test[['click_id', 'features']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBT Classifier -- all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtc = GBTClassifier(\n",
    "    labelCol = 'is_attributed',\n",
    "    maxDepth = 8,\n",
    "    minInstancesPerNode = 16,\n",
    "    maxIter = 15,\n",
    "    stepSize = 0.7,\n",
    "    subsamplingRate = .9,\n",
    "    featureSubsetStrategy = '13'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = gbtc.fit(vf_a)\n",
    "model_b = gbtc.fit(vf_b)\n",
    "model_c = gbtc.fit(vf_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save models for possible stacking later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.save('../data/model/model_a.model')\n",
    "model_b.save('../data/model/model_b.model')\n",
    "model_c.save('../data/model/model_c.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test data through the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_a = model_a.transform(vf_test)\n",
    "results_b = model_b.transform(vf_test)\n",
    "results_c = model_c.transform(vf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv to submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the median probability of class 1\n",
    "# from three probability vectors \n",
    "def get_median(a, b, c):\n",
    "    a = a[1]\n",
    "    b = b[1]\n",
    "    c = c[1]\n",
    "    if a > b and a < c:\n",
    "        return float(a)\n",
    "    if b > a and b < c:\n",
    "        return float(b)\n",
    "    return float(c)\n",
    "\n",
    "udf_get_median = F.udf(get_median, T.FloatType())\n",
    "\n",
    "def merge_results(a, b, c):\n",
    "\n",
    "    a.createOrReplaceTempView('a_result')\n",
    "    b.createOrReplaceTempView('b_result')\n",
    "    c.createOrReplaceTempView('c_result')\n",
    "\n",
    "    join = spark.sql(\"\"\"\n",
    "    \n",
    "    SELECT  a_result.click_id    AS click_id, \n",
    "            a_result.probability AS a_prob, \n",
    "            b_result.probability AS b_prob, \n",
    "            c_result.probability AS c_prob\n",
    "    FROM\n",
    "             a_result \n",
    "        JOIN b_result \n",
    "          ON a_result.click_id = b_result.click_id\n",
    "        JOIN c_result\n",
    "          ON a_result.click_id = c_result.click_id\n",
    "    \"\"\")\n",
    "    \n",
    "    join.show(5)\n",
    "\n",
    "    result = join.select('click_id',\n",
    "         udf_get_median('a_prob','b_prob','c_prob').alias('is_attributed'))\n",
    "\n",
    "    result.show(5)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|click_id|              a_prob|              b_prob|              c_prob|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|     148|[0.94539376085098...|[0.94779208087944...|[0.94379030731756...|\n",
      "|     463|[0.94176715437250...|[0.94205247058463...|[0.94349557916544...|\n",
      "|     471|[0.97981014861923...|[0.98209989159970...|[0.98021108158768...|\n",
      "|     496|[0.96949655694921...|[0.97259814020590...|[0.97057270775433...|\n",
      "|     833|[0.98114177498547...|[0.97768255943114...|[0.97394636623424...|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+-------------+\n",
      "|click_id|is_attributed|\n",
      "+--------+-------------+\n",
      "|     148|   0.05460624|\n",
      "|     463|   0.05650442|\n",
      "|     471|  0.019788919|\n",
      "|     496|  0.029427292|\n",
      "|     833|  0.022317441|\n",
      "+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = merge_results(results_a, results_b, results_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.csv('../data/kaggle/submit_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBT Classifier - Top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtc = GBTClassifier(\n",
    "    labelCol = 'is_attributed',\n",
    "    maxDepth = 8,\n",
    "    minInstancesPerNode = 16,\n",
    "    maxIter = 15,\n",
    "    stepSize = 0.7,\n",
    "    subsamplingRate = .9,\n",
    "    featureSubsetStrategy = '9'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = gbtc.fit(topv_a)\n",
    "model_b = gbtc.fit(topv_b)\n",
    "model_c = gbtc.fit(topv_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save models for possible stacking later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.save('../data/model/topf_model_a.model')\n",
    "model_b.save('../data/model/topf_model_b.model')\n",
    "model_c.save('../data/model/topf_model_c.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test data through the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_a = model_a.transform(topv_test)\n",
    "results_b = model_b.transform(topv_test)\n",
    "results_c = model_c.transform(topv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|click_id|is_attributed|\n",
      "+--------+-------------+\n",
      "|     148|   0.06027116|\n",
      "|     463|  0.057876226|\n",
      "|     471|  0.020789148|\n",
      "|     496|   0.02852715|\n",
      "|     833|  0.022072932|\n",
      "+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create csv to submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = merge_results(results_a, results_b, results_c)\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.write.csv('../data/kaggle/submit_topfeat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-5572cac05c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# barrier so I don't hit return too many times and kill my spark session :-)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# barrier so I don't hit return too many times and kill my spark session :-)\n",
    "assert(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
